{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MENJSpOGWRNN"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import udf,col\n",
        "\n",
        "from pyspark.sql.types import StringType,BooleanType,IntegerType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Spark udf example\").getOrCreate()\n",
        "\n",
        "\n",
        "df=spark.createDataFrame(data, Schema)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(1,\"nadiya\",65000,500,),(12,\"Ayesha\",56000,600),(6,\"Bujji\",165000,1500),(9,\"Vanisha\",565000,2500),(10,\"nadi\",16500,580)]"
      ],
      "metadata": {
        "id": "dmp7LaoOXtf9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Schema=['id','name','salary','bonus']\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLOJEPeNYyIU",
        "outputId": "dfe24ba6-0318-41dd-bf71-441b90320695"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+-----+\n",
            "| id|   name|salary|bonus|\n",
            "+---+-------+------+-----+\n",
            "|  1| nadiya| 65000|  500|\n",
            "| 12| Ayesha| 56000|  600|\n",
            "|  6|  Bujji|165000| 1500|\n",
            "|  9|Vanisha|565000| 2500|\n",
            "| 10|   nadi| 16500|  580|\n",
            "+---+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# Define your function\n",
        "def totalpay(salary, bonus):\n",
        "    return salary + bonus if salary is not None and bonus is not None else 0\n",
        "\n",
        "\n",
        "# Create the UDF\n",
        "Totalpay = udf(lambda a, b: totalpay(a, b), IntegerType())\n",
        "\n",
        "# Apply UDF to create the new column\n",
        "df = df.withColumn(\"Totalpay\", Totalpay(df[\"Salary\"], df[\"bonus\"]))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brcMpcYGtFQr",
        "outputId": "d82bc012-1431-43ef-ff6e-130553fe0e79"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+------+-----+--------+\n",
            "| id|   name|salary|bonus|Totalpay|\n",
            "+---+-------+------+-----+--------+\n",
            "|  1| nadiya| 65000|  500|   65500|\n",
            "| 12| Ayesha| 56000|  600|   56600|\n",
            "|  6|  Bujji|165000| 1500|  166500|\n",
            "|  9|Vanisha|565000| 2500|  567500|\n",
            "| 10|   nadi| 16500|  580|   17080|\n",
            "+---+-------+------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "from pyspark.sql.types import StringType, BooleanType\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Spark4Features\").getOrCreate()\n",
        "\n",
        "df1 = spark.range(5)\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpQlOJi9uhBY",
        "outputId": "8d04de15-f83a-4147-8699-6642715c832a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  0|\n",
            "|  1|\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df2 = spark.createDataFrame([(\"10\",), (\"abc\",)], [\"value\"])\n",
        "df2.selectExpr(\"CAST(value AS INT)\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD4v90seumVx",
        "outputId": "d619ba1a-024d-4fb7-9e0f-b4158a392a58"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|value|\n",
            "+-----+\n",
            "|   10|\n",
            "| NULL|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df3 = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 1).load()\n",
        "df3.selectExpr(\"timestamp\", \"value\", \"value % 2 as is_even\").writeStream.format(\"console\").start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sekDbIKJu94U",
        "outputId": "f233540b-2539-4c4c-8d1f-a0068f520a8d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.streaming.query.StreamingQuery at 0x7a3b82d72690>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df4 = spark.createDataFrame([(\"Zimmy\",), (\"Snoopi\",), (\"puffy\",)], [\"name\"])\n",
        "df4.orderBy(col(\"name\").asc()).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWE9wV8dvQ92",
        "outputId": "b34fe6fa-e837-4e5b-aa17-fed0431f2748"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|  name|\n",
            "+------+\n",
            "|Snoopi|\n",
            "| Zimmy|\n",
            "| puffy|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Spark4Features\").getOrCreate()\n",
        "\n",
        "df5 = spark.createDataFrame([({\"key\": \"value\"},), ({\"number\": 10},)], [\"data\"])\n",
        "df5.withColumn(\"data_as_string\", expr(\"CAST(data AS STRING)\")).show()\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HhuTbotvY0J",
        "outputId": "910b33dd-12c1-4697-e465-64528b5d09c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------+\n",
            "|          data|data_as_string|\n",
            "+--------------+--------------+\n",
            "|{key -> value}|{key -> value}|\n",
            "|{number -> 10}|{number -> 10}|\n",
            "+--------------+--------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}